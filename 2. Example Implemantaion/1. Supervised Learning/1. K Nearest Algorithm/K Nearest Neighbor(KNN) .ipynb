{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K Nearest Neighbor(KNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Necessary Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data to Matrix and Map it to Numeric Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the file and convert it to numpy matrix.\n",
    "\n",
    "# Load necessary modules\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "\n",
    "\n",
    "def load_text_data(file, delimiter, header, label_col_is_str , label_col):\n",
    "    \"\"\"\n",
    "    Loading the text data and convert it to numpy matrix.\n",
    "    If there is a label column with string data type, it will convert the label to Intiger and replace the string. And also return\n",
    "    the mapping of the string mapping in a dictionary.\n",
    "    \n",
    "    Input:\n",
    "    file: file name\n",
    "    delimiter: \",\" or \"\\t\" etc.\n",
    "    header : True / False\n",
    "    label_col_is_str: True/ False\n",
    "    label_col : the column index of the label.\n",
    "    \n",
    "    Output:\n",
    "    \n",
    "    Data: in numpy matrix.\n",
    "    label_map: in dictionary.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    text_file = open(file, \"rt\")\n",
    "    reader = csv.reader(text_file, delimiter = delimiter)\n",
    "    x = list(reader)\n",
    "    text_file.close()\n",
    "    \n",
    "    # if there is a header, remove it.\n",
    "    if header:\n",
    "        x.pop(0)\n",
    "    Data = np.asmatrix(x)\n",
    "    \n",
    "    if label_col_is_str:\n",
    "        try:\n",
    "            Data, Label_Map = map_label(Data, label_col)\n",
    "            return Data, Label_Map\n",
    "        except ValueError:\n",
    "            print(\"The header is string data type. Please specify the header = True in the function.\")\n",
    "            Data = None\n",
    "    else:\n",
    "        return Data\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# mapping of the string labels.\n",
    "\n",
    "\n",
    "# mapping the label\n",
    "def map_label(Data, label_column):\n",
    "    \"\"\"\n",
    "    If the label column is string, create a map for the label and convert it to intiger.\n",
    "    \n",
    "    Input:\n",
    "    1. Data: in numpy matrix.\n",
    "    2. label_column: the column number containing the label.\n",
    "    \n",
    "    Output:\n",
    "    1. Data: in numpy matrix in float data type.\n",
    "    \"\"\"\n",
    "    Label_Map = {}\n",
    "    \n",
    "    Label = np.unique(np.array(Data[:, label_column]))\n",
    "    \n",
    "    for i in range(len(Label)):\n",
    "        Label_Map[Label[i]] = i\n",
    "    \n",
    "    mapping = lambda label, label_map : label_map[label]\n",
    "    \n",
    "    Data[:, label_column] = np.vectorize(mapping)(Data[:, label_column], Label_Map)\n",
    "    \n",
    "    Data = Data.astype(float) \n",
    "    \n",
    "    return Data, Label_Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the Data to Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-test data\n",
    "class split_train_test:\n",
    "\n",
    "    \n",
    "    \n",
    "    def __init__(self, data, percentage, label):\n",
    "        '''\n",
    "        Input:\n",
    "        data: a numpy matrix.\n",
    "        percentage: percentage of samples for the training. percentage must be greater than 0 and less than 100.\n",
    "        label: column index of the label.\n",
    "        \n",
    "        \n",
    "        '''\n",
    "\n",
    "        # import necessary module\n",
    "\n",
    "        import numpy as np\n",
    "\n",
    "        # make an one dimensional matrix n*1 to a vecto\n",
    "\n",
    "        make_vector = lambda X : np.squeeze(np.asarray(X))\n",
    "\n",
    "\n",
    "        if percentage <= 0 or percentage >= 100:\n",
    "            print(\"The percentage of training data must be greater than 0 and less than 100.\")\n",
    "        else:\n",
    "            import random;\n",
    "        \n",
    "            n = data.shape[0]  # take the number of rows in original data.\n",
    "            l = int(n*percentage/100)\n",
    "        \n",
    "        \n",
    "            # Take random integers to slice the data\n",
    "            train_rows = random.sample(range(n), l)\n",
    "            test_rows  = [i for i in range(n) if i not in train_rows]\n",
    "            \n",
    "            # Split the data to train and test.\n",
    "            self.train = data[train_rows,:]\n",
    "            self.test  = data[test_rows, :]\n",
    "            \n",
    "            # Split both train and test data to feature and label.\n",
    "            self.train_feature = np.delete(self.train, label, 1)\n",
    "            self.train_label = make_vector(self.train[:, label])\n",
    "            \n",
    "            # Split both train and test data to feature and label.\n",
    "            self.test_feature = np.delete(self.test, label, 1)\n",
    "            self.test_label = make_vector(self.test[:, label])\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "## Function for euclidean Distance\n",
    "def euclidean_distance(x, y):\n",
    "    # import math\n",
    "    if len(x) != len(y):\n",
    "        print('Length of two features/vectors are not same.')\n",
    "    else:\n",
    "        n = len(x)\n",
    "        d2 = 0\n",
    "        for i in range(n):\n",
    "            d2 = d2 + (x[i] - y[i])**2\n",
    "        d = math.sqrt(d2)\n",
    "    \n",
    "    return d\n",
    "\n",
    "\n",
    "\n",
    "def K_nearest_neighbour(feature_sample, feature_label, test_sample, k):\n",
    "    \n",
    "    \"\"\"\n",
    "    Input: \n",
    "    feature_sample: feature matrix, returned from train test split. in numpy matrix\n",
    "    feature_label : feature label matrix, returned from train test split. in numpy matrix\n",
    "    test_sample :   test feature matrix, returned from train test split. in numpy matrix\n",
    "    k : number of items to be considered as \"nearest neighbours.\" Data type: intiger.\n",
    "    \n",
    "    Output:\n",
    "    Predicted label: A list of predicted lables corresponding to the given feature.\n",
    "    \n",
    "    In the implementation \"np.squeeze(np.asarray(MATRIX))\" was used to convert matrix to array for easy of calculation.\n",
    "    \"\"\"\n",
    "    \n",
    "    m = test_sample.shape[0]                        # number of samples in the test data.\n",
    "    n = feature_sample.shape[0]                     # number of samples in the train data\n",
    "    \n",
    "    predicted_label_list = [] \n",
    "    \n",
    "    for i in range(m):\n",
    "        X = test_sample[i,:]\n",
    "        \n",
    "        D = np.full([n,2], np.nan)                  # make an empty matrix to store feature label and corresponding distance. 1st Column \n",
    "                                                    # is for label and 2nd column is for corresponding distance from the test feature.\n",
    "        D[:, 0] = np.squeeze(np.asarray(feature_label))\n",
    "        \n",
    "        for j in range(n):\n",
    "            D[j,1] = euclidean_distance(np.squeeze(np.asarray(X)), np.squeeze(np.asarray(feature_sample[j,:])))\n",
    "        \n",
    "        Z = D[np.argsort(D[:, 1]),][:, 0]\n",
    "        Z = Z[0:k]\n",
    "\n",
    "        lab, count = np.unique(Z, return_counts = True)\n",
    "        \n",
    "        predicted_label = lab[np.argsort(count)[0],]\n",
    "        \n",
    "        predicted_label_list.append(predicted_label)\n",
    "        \n",
    "    return predicted_label_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance and Accurace Measurement "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(true_label, pred_label, percentage = True):\n",
    "    \"\"\"\n",
    "    Input: \n",
    "    1. true_label: The True label.\n",
    "    2. pred_label: The predicted label.\n",
    "    3. percentage: If the result wanted in percentage. True/False\n",
    "    \n",
    "    Output:\n",
    "    1. total accuracy\n",
    "    2. confusion table. True label * Predicted label\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    import numpy as np\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "    if len(pred_label) == len(true_label):\n",
    "        n = len(pred_label)\n",
    "        accuracy = round((sum(np.asarray(pred_label) == np.asarray(true_label))/n) * 100, 2)\n",
    "        \n",
    "        p_l = np.unique(pred_label)\n",
    "        t_l = np.unique(true_label)\n",
    "        n = len(p_l)\n",
    "        confusion_matrix = np.zeros([n, n])\n",
    "\n",
    "        for i in range(n):\n",
    "            t = t_l[i]\n",
    "            for j in range(n):\n",
    "                p = p_l[j]\n",
    "                c = sum([pred_label[k] == p and true_label[k] == t for k in range(len(pred_label))])\n",
    "                confusion_matrix[i,j] = c\n",
    "        \n",
    "        if percentage:\n",
    "            confusion_matrix = np.around((confusion_matrix/len(pred_label)) * 100, decimals = 2)\n",
    "        \n",
    "        \n",
    "        \n",
    "        return accuracy, confusion_matrix\n",
    "\n",
    "\n",
    "\n",
    "    else:\n",
    "        print(\"Predicted label and True label lengths are not same.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation with Iris Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r\"C:\\Users\\tahsi\\OneDrive - University of Eastern Finland\\Python Algorithm and Data Structure\\GitHub\\ml-algorithms-python-numpy\\1. Codes\")\n",
    "Iris, d_map = load_text_data(file = \"Iris.txt\", delimiter = \",\", header = False , label_col_is_str = True , label_col = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.1 3.5 1.4 0.2 0. ]\n",
      " [4.9 3.  1.4 0.2 0. ]\n",
      " [4.7 3.2 1.3 0.2 0. ]\n",
      " [4.6 3.1 1.5 0.2 0. ]\n",
      " [5.  3.6 1.4 0.2 0. ]]\n"
     ]
    }
   ],
   "source": [
    "# first 5 rows of the data. The 5th column was the label. The label was string. The function mapped it to integer. The map of label\n",
    "# is stored in the d_map\n",
    "print(Iris[0:5 ,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Iris-setosa': 0, 'Iris-versicolor': 1, 'Iris-virginica': 2}\n"
     ]
    }
   ],
   "source": [
    "print(d_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Split the Data to Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_data = split_train_test(data = Iris, percentage = 50, label = 4)\n",
    "\n",
    "train_data_feature = train_test_data.train_feature\n",
    "train_data_label = train_test_data.train_label\n",
    "test_feature = train_test_data.test_feature\n",
    "true_label = train_test_data.test_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Implementation of KNN Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_label = K_nearest_neighbour(feature_sample = train_data_feature, feature_label = train_data_label, test_sample = test_feature, k = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Performance Measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "acuraccy, con_table = confusion_matrix(true_label = true_label, pred_label = predicted_label, percentage = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69.33\n"
     ]
    }
   ],
   "source": [
    "print(acuraccy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[32.    0.    0.  ]\n",
      " [ 0.   21.33 16.  ]\n",
      " [ 0.   14.67 16.  ]]\n"
     ]
    }
   ],
   "source": [
    "print(con_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
