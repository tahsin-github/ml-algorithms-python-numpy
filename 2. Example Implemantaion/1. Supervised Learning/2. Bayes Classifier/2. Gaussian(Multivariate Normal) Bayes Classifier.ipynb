{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian(Multivariate Normal) Bayes Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Necessary Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data to Matrix and Map it to Numeric Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the file and convert it to numpy matrix.\n",
    "\n",
    "# Load necessary modules\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "\n",
    "\n",
    "def load_text_data(file, delimiter, header, label_col_is_str , label_col):\n",
    "    \"\"\"\n",
    "    Loading the text data and convert it to numpy matrix.\n",
    "    If there is a label column with string data type, it will convert the label to Intiger and replace the string. And also return\n",
    "    the mapping of the string mapping in a dictionary.\n",
    "    \n",
    "    Input:\n",
    "    file: file name\n",
    "    delimiter: \",\" or \"\\t\" etc.\n",
    "    header : True / False\n",
    "    label_col_is_str: True/ False\n",
    "    label_col : the column index of the label.\n",
    "    \n",
    "    Output:\n",
    "    \n",
    "    Data: in numpy matrix.\n",
    "    label_map: in dictionary.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    text_file = open(file, \"rt\")\n",
    "    reader = csv.reader(text_file, delimiter = delimiter)\n",
    "    x = list(reader)\n",
    "    text_file.close()\n",
    "    \n",
    "    # if there is a header, remove it.\n",
    "    if header:\n",
    "        x.pop(0)\n",
    "    Data = np.asmatrix(x)\n",
    "    \n",
    "    if label_col_is_str:\n",
    "        try:\n",
    "            Data, Label_Map = map_label(Data, label_col)\n",
    "            return Data, Label_Map\n",
    "        except ValueError:\n",
    "            print(\"The header is string data type. Please specify the header = True in the function.\")\n",
    "            Data = None\n",
    "    else:\n",
    "        return Data\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# mapping of the string labels.\n",
    "\n",
    "\n",
    "# mapping the label\n",
    "def map_label(Data, label_column):\n",
    "    \"\"\"\n",
    "    If the label column is string, create a map for the label and convert it to intiger.\n",
    "    \n",
    "    Input:\n",
    "    1. Data: in numpy matrix.\n",
    "    2. label_column: the column number containing the label.\n",
    "    \n",
    "    Output:\n",
    "    1. Data: in numpy matrix in float data type.\n",
    "    \"\"\"\n",
    "    Label_Map = {}\n",
    "    \n",
    "    Label = np.unique(np.array(Data[:, label_column]))\n",
    "    \n",
    "    for i in range(len(Label)):\n",
    "        Label_Map[Label[i]] = i\n",
    "    \n",
    "    mapping = lambda label, label_map : label_map[label]\n",
    "    \n",
    "    Data[:, label_column] = np.vectorize(mapping)(Data[:, label_column], Label_Map)\n",
    "    \n",
    "    Data = Data.astype(float) \n",
    "    \n",
    "    return Data, Label_Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the Data to Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-test data\n",
    "class split_train_test:\n",
    "\n",
    "    \n",
    "    \n",
    "    def __init__(self, data, percentage, label):\n",
    "        '''\n",
    "        Input:\n",
    "        data: a numpy matrix.\n",
    "        percentage: percentage of samples for the training. percentage must be greater than 0 and less than 100.\n",
    "        label: column index of the label.\n",
    "        \n",
    "        \n",
    "        '''\n",
    "\n",
    "        # import necessary module\n",
    "\n",
    "        import numpy as np\n",
    "\n",
    "        # make an one dimensional matrix n*1 to a vecto\n",
    "\n",
    "        make_vector = lambda X : np.squeeze(np.asarray(X))\n",
    "\n",
    "\n",
    "        if percentage <= 0 or percentage >= 100:\n",
    "            print(\"The percentage of training data must be greater than 0 and less than 100.\")\n",
    "        else:\n",
    "            import random;\n",
    "        \n",
    "            n = data.shape[0]  # take the number of rows in original data.\n",
    "            l = int(n*percentage/100)\n",
    "        \n",
    "        \n",
    "            # Take random integers to slice the data\n",
    "            train_rows = random.sample(range(n), l)\n",
    "            test_rows  = [i for i in range(n) if i not in train_rows]\n",
    "            \n",
    "            # Split the data to train and test.\n",
    "            self.train = data[train_rows,:]\n",
    "            self.test  = data[test_rows, :]\n",
    "            \n",
    "            # Split both train and test data to feature and label.\n",
    "            self.train_feature = np.delete(self.train, label, 1)\n",
    "            self.train_label = make_vector(self.train[:, label])\n",
    "            \n",
    "            # Split both train and test data to feature and label.\n",
    "            self.test_feature = np.delete(self.test, label, 1)\n",
    "            self.test_label = make_vector(self.test[:, label])\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian(Multivariate Normal) Bayes Classifier Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training of the model.\n",
    "\n",
    "def train_naive_bayes(train_data, label):\n",
    "    \n",
    "    \"\"\"\n",
    "    Input:\n",
    "    1. train_data: the train data with the label column. The data must be in 2d array(not matrix).\n",
    "    2. label: the column index of the label in the train_data.\n",
    "    \n",
    "    Output:\n",
    "    1. mean: the mean vector of the features in dictionary.\n",
    "    2. covariance: the covariance of the features in dictionary.\n",
    "    3. prior_prob : the prior probability of each of the labels dictionary.\n",
    "    4. class_label : label of the classes.\n",
    "    \n",
    "    In output dictionary the keys are the label.\n",
    "    \"\"\"\n",
    "\n",
    "    import numpy as np\n",
    "\n",
    "    # Storing mean and variances of each of the features of each of the classes in dictionary.\n",
    "    \n",
    "    # Train Model.\n",
    "\n",
    "    # Storing mean and variances of each of the features of each of the classes in dictionary.\n",
    "    mean = {}\n",
    "    covariance  = {}\n",
    "    prior_prob = {}\n",
    "\n",
    "\n",
    "    \n",
    "    N = train_data.shape[0]\n",
    "    class_labels = np.unique(train_data[:, label])\n",
    "    for i in class_labels:\n",
    "        X = train_data[train_data[:, label] == i, :] # make seperate matrix for each of the classes.\n",
    "        X_features = np.delete(X, label, axis = 1)       # delete the class column and take only the features.\n",
    "        mean[i] = X_features.mean(0)                 # means of the features\n",
    "        covariance[i]  = np.cov(X_features.T)        # covariances of the features\n",
    "        prior_prob[i] = X_features.shape[0]/N\n",
    "\n",
    "\n",
    "            \n",
    "    return mean, covariance, prior_prob, class_labels\n",
    "    \n",
    "\n",
    "\n",
    "# Testing\n",
    "\n",
    "# Normal Likelihood\n",
    "\n",
    "def multivariate_gaussian_likelihood(x, mu, sigma):\n",
    "    \n",
    "    import numpy as np\n",
    "    import math\n",
    "    \n",
    "    p = len(x)\n",
    "    \n",
    "    p1 =  1 / (pow(2 * (math.pi), p/2) * np.linalg.det(sigma))\n",
    "\n",
    "    X = np.asmatrix(x - mu)\n",
    "    Y = np.asmatrix(np.linalg.inv(sigma))\n",
    "    p2 = math.exp(-0.5 * np.dot(np.dot(X,Y), X.T))\n",
    "\n",
    "    return p1*p2\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "# Bayes Numerator\n",
    "\n",
    "def bayes_numerator(likelihood, prior):\n",
    "    return likelihood * prior\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def gaussian_bayes_classification(test_feature, mean, covariance, prior_prob, class_labels):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "    1. test_feature: the test features in 2D array(not matrix).\n",
    "    2. mean: the mean vector of the features in dictionary.(from the training step)\n",
    "    3. covariance: the covariance of the features in dictionary.(from the training step)\n",
    "    4. prior_prob : the prior probability of each of the labels dictionary.(from the training step)\n",
    "    Output:\n",
    "    The predicted label in list.\n",
    "    \"\"\"\n",
    "\n",
    "    import numpy as np\n",
    "\n",
    "    pred_label = []\n",
    "\n",
    "    # Test the data\n",
    "    for i in range(len(test_feature)):\n",
    "        x = test_feature[i]\n",
    "\n",
    "        class_compare = np.empty([len(class_labels), 3])\n",
    "        class_compare[:] = np.nan\n",
    "        class_compare[:, 0] = class_labels\n",
    "\n",
    "        bayes_numerator_all_class = [multivariate_gaussian_likelihood(x, mean[i], covariance[i]) for i in class_labels]\n",
    "\n",
    "        normalizing_factor = sum(bayes_numerator_all_class)\n",
    "\n",
    "        posterior_porb = [bayes_numerator_all_class[i]/ normalizing_factor for i in range(len(bayes_numerator_all_class))]\n",
    "\n",
    "        class_compare[:, 1] = bayes_numerator_all_class\n",
    "        class_compare[:, 2] = posterior_porb\n",
    "\n",
    "        \n",
    "\n",
    "        maximum_posterior =  max(class_compare[:, 2])\n",
    "\n",
    "        c = class_compare[class_compare[:,2] == maximum_posterior,][0][0]\n",
    "\n",
    "        pred_label.append(c)\n",
    "    \n",
    "    return pred_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance and Accurace Measurement "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(true_label, pred_label, percentage = True):\n",
    "    \"\"\"\n",
    "    Input: \n",
    "    1. true_label: The True label.\n",
    "    2. pred_label: The predicted label.\n",
    "    3. percentage: If the result wanted in percentage. True/False\n",
    "    \n",
    "    Output:\n",
    "    1. total accuracy\n",
    "    2. confusion table. True label * Predicted label\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    import numpy as np\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "    if len(pred_label) == len(true_label):\n",
    "        n = len(pred_label)\n",
    "        accuracy = round((sum(np.asarray(pred_label) == np.asarray(true_label))/n) * 100, 2)\n",
    "        \n",
    "        p_l = np.unique(pred_label)\n",
    "        t_l = np.unique(true_label)\n",
    "        n = len(p_l)\n",
    "        confusion_matrix = np.zeros([n, n])\n",
    "\n",
    "        for i in range(n):\n",
    "            t = t_l[i]\n",
    "            for j in range(n):\n",
    "                p = p_l[j]\n",
    "                c = sum([pred_label[k] == p and true_label[k] == t for k in range(len(pred_label))])\n",
    "                confusion_matrix[i,j] = c\n",
    "        \n",
    "        if percentage:\n",
    "            confusion_matrix = np.around((confusion_matrix/len(pred_label)) * 100, decimals = 2)\n",
    "        \n",
    "        \n",
    "        \n",
    "        return accuracy, confusion_matrix\n",
    "\n",
    "\n",
    "\n",
    "    else:\n",
    "        print(\"Predicted label and True label lengths are not same.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation with Iris Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r\"C:\\Users\\tahsi\\OneDrive - University of Eastern Finland\\Python Algorithm and Data Structure\\GitHub\\ml-algorithms-python-numpy\\1. Codes\")\n",
    "Iris, d_map = load_text_data(file = \"Iris.txt\", delimiter = \",\", header = False , label_col_is_str = True , label_col = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.1 3.5 1.4 0.2 0. ]\n",
      " [4.9 3.  1.4 0.2 0. ]\n",
      " [4.7 3.2 1.3 0.2 0. ]\n",
      " [4.6 3.1 1.5 0.2 0. ]\n",
      " [5.  3.6 1.4 0.2 0. ]]\n"
     ]
    }
   ],
   "source": [
    "# first 5 rows of the data. The 5th column was the label. The label was string. The function mapped it to integer. The map of label\n",
    "# is stored in the d_map\n",
    "print(Iris[0:5 ,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Iris-setosa': 0, 'Iris-versicolor': 1, 'Iris-virginica': 2}\n"
     ]
    }
   ],
   "source": [
    "print(d_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Split the Data to Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_data = split_train_test(data = Iris, percentage = 50, label = 4)\n",
    "\n",
    "train_data_feature = train_test_data.train_feature\n",
    "train_data_label = train_test_data.train_label\n",
    "test_feature = np.asarray(train_test_data.test_feature) \n",
    "true_label = np.asarray(train_test_data.test_label)\n",
    "train_data_feature_label = np.asarray(train_test_data.train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Implementation of Gaussian(Multivariate Normal) Bayes Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data_feature_label\n",
    "label = 4\n",
    "mean, covariance, prior_prob, class_labels = train_naive_bayes(train_data, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_label = gaussian_bayes_classification(test_feature , mean, covariance, prior_prob, class_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Performance Measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "acuraccy, con_table = confusion_matrix(true_label = true_label, pred_label = predicted_label, percentage = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97.33\n"
     ]
    }
   ],
   "source": [
    "print(acuraccy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[36.    0.    0.  ]\n",
      " [ 0.   26.67  2.67]\n",
      " [ 0.    0.   34.67]]\n"
     ]
    }
   ],
   "source": [
    "print(con_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
