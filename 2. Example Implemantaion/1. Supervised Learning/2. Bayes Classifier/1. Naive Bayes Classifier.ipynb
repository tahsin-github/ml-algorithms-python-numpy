{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Classifier Example Dataset : Iris\n",
    "## Import Necesary Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(r\"C:\\Users\\tahsi\\OneDrive - University of Eastern Finland\\Python Algorithm and Data Structure\\GitHub\\ml-algorithms-python-numpy\\1. Codes\")\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import load_data_to_matrix, split_train_test, int_label_to_str_label, performance_measurement, k_means_algorithm, distance_measurement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from load_data_to_matrix import load_text_data, map_label\n",
    "Iris, d_map = load_text_data(file = \"Iris.txt\", delimiter = \",\", header = False , label_col_is_str = True , label_col = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.1 3.5 1.4 0.2 0. ]\n",
      " [4.9 3.  1.4 0.2 0. ]\n",
      " [4.7 3.2 1.3 0.2 0. ]\n",
      " [4.6 3.1 1.5 0.2 0. ]\n",
      " [5.  3.6 1.4 0.2 0. ]]\n"
     ]
    }
   ],
   "source": [
    "# first 5 rows of the data. The 5th column was the label. The label was string. The function mapped it to integer. The map of label\n",
    "# is stored in the d_map\n",
    "print(Iris[0:5 ,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Iris-setosa': 0, 'Iris-versicolor': 1, 'Iris-virginica': 2}\n"
     ]
    }
   ],
   "source": [
    "print(d_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the Data to Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from split_train_test import split_train_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_data = split_train_test(data = Iris, percentage = 20, label = 4)\n",
    "\n",
    "train_data_feature = train_test_data.train_feature\n",
    "train_data_label = train_test_data.train_label\n",
    "test_feature = np.asarray(train_test_data.test_feature) \n",
    "true_label = np.asarray(train_test_data.test_label)\n",
    "train_data_feature_label = np.asarray(train_test_data.train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from naive_bayes_classifier import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data_feature_label\n",
    "label = 4\n",
    "mean, var, prior_prob, class_labels = train_naive_bayes(train_data, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_label = naive_bayes_classification(test_feature, mean, var, prior_prob, class_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance Measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from performance_measurement import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "acuraccy, con_table = confusion_matrix(true_label = true_label, pred_label = predicted_label, percentage = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91.67\n"
     ]
    }
   ],
   "source": [
    "print(acuraccy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[30.83  0.    0.  ]\n",
      " [ 0.   30.83  7.5 ]\n",
      " [ 0.    0.83 30.  ]]\n"
     ]
    }
   ],
   "source": [
    "print(con_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code of the Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training of the model.\n",
    "\n",
    "def train_naive_bayes(train_data, label):\n",
    "    \n",
    "    \"\"\"\n",
    "    Input:\n",
    "    1. train_data: the train data with the label column. The data must be in 2d array(not matrix).\n",
    "    2. label: the column index of the label in the train_data\n",
    "    \n",
    "    Output:\n",
    "    1. mean: the mean vector of the features in dictionary.\n",
    "    2. var: the variance vector of the features in dictionary.\n",
    "    3. prior_prob : the prior probability of each of the labels dictionary.\n",
    "    4. class_label : label of the classes.\n",
    "    \n",
    "    In output dictionary the keys are the label.\n",
    "    \"\"\"\n",
    "\n",
    "    import numpy as np\n",
    "\n",
    "    # Storing mean and variances of each of the features of each of the classes in dictionary.\n",
    "    \n",
    "    mean = {}\n",
    "    var  = {}\n",
    "    prior_prob = {}\n",
    "    \n",
    "    \n",
    "\n",
    "    N = train_data.shape[0]\n",
    "    class_labels = np.unique(train_data[:, label])\n",
    "    for i in class_labels:\n",
    "        X = train_data[train_data[:, label] == i, :] # make seperate matrix for each of the classes.\n",
    "        X_features = np.delete(X, label, axis = 1)       # delete the class column and take only the features.\n",
    "        mean[i] = X_features.mean(0)                 # means of the features\n",
    "        var[i]  = X_features.var(0)                  # variances of the features\n",
    "        prior_prob[i] = X_features.shape[0]/N\n",
    "        \n",
    "    return mean, var, prior_prob, class_labels\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "# Tesing the model\n",
    "\n",
    "def naive_bayes_classification(test_feature, mean, var, prior_prob, class_labels):\n",
    "    \n",
    "    \"\"\"\n",
    "    Input:\n",
    "    1. test_feature: the test data in 2d array.\n",
    "    2. mean : means of each of the class in dictionary. [returned from the training step]\n",
    "    3. var  : variance of each of the class in dictionary.[returned from the training step]\n",
    "    4. prior_prob: prior probariliy of each of the class in dictionary.[returned from the training step]\n",
    "    5. class_labels : the class labels of the training data.[returned from the training step]\n",
    "    \n",
    "        \n",
    "    Output:\n",
    "    1. Predicted Label in a list.\n",
    "    \"\"\"\n",
    "    \n",
    "    import math\n",
    "    import numpy as np\n",
    "    \n",
    "    \n",
    "    pred_label = []\n",
    "    \n",
    "    \n",
    "    for i in range(len(test_feature)):\n",
    "        x = test_feature[i]\n",
    "\n",
    "        class_compare = np.empty([len(class_labels), 3])\n",
    "        class_compare[:] = np.nan\n",
    "        class_compare[:, 0] = class_labels\n",
    "\n",
    "        bayes_numerator_all_class = []\n",
    "\n",
    "        bayes_numerator_all_class = [bayes_numerator(x, mu = mean[i], variance = var[i], prior = prior_prob[i]) for i in class_labels]\n",
    "\n",
    "        normalizing_factor = sum(bayes_numerator_all_class)\n",
    "\n",
    "        posterior_porb = [bayes_numerator_all_class[i]/ normalizing_factor for i in range(len(bayes_numerator_all_class))]\n",
    "\n",
    "        class_compare[:, 1] = bayes_numerator_all_class\n",
    "        class_compare[:, 2] = posterior_porb\n",
    "        maximum_posterior =  max(class_compare[:, 2])\n",
    "        c = class_compare[class_compare[:,2] == maximum_posterior,][0][0]\n",
    "\n",
    "        pred_label.append(c)\n",
    "        \n",
    "        \n",
    "    return pred_label\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "# Testing\n",
    "# The likelihood function.\n",
    "def normal_likelihood(x, mu, var):\n",
    "    import math\n",
    "    \n",
    "    p1 = 1/ math.sqrt(var * 2 * math.pi)\n",
    "    p2 = math.exp(-0.5 * pow((x - mu), 2)/var)\n",
    "    \n",
    "    return (p1*p2)\n",
    "    \n",
    "\n",
    "# The Bayes Numerator\n",
    "def bayes_numerator(x, mu, variance, prior):\n",
    "    import numpy as np\n",
    "    likelihood = [normal_likelihood(x[i], mu[i], variance[i]) for i in range(len(x))]\n",
    "    bayes_numerator = np.prod(likelihood) * prior\n",
    "    \n",
    "    return bayes_numerator\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
