{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K Means Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Necessary Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data to Matrix and Map it to Numeric Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the file and convert it to numpy matrix.\n",
    "\n",
    "# Load necessary modules\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "\n",
    "\n",
    "def load_text_data(file, delimiter, header, label_col_is_str , label_col):\n",
    "    \"\"\"\n",
    "    Loading the text data and convert it to numpy matrix.\n",
    "    If there is a label column with string data type, it will convert the label to Intiger and replace the string. And also return\n",
    "    the mapping of the string mapping in a dictionary.\n",
    "    \n",
    "    Input:\n",
    "    file: file name\n",
    "    delimiter: \",\" or \"\\t\" etc.\n",
    "    header : True / False\n",
    "    label_col_is_str: True/ False\n",
    "    label_col : the column index of the label.\n",
    "    \n",
    "    Output:\n",
    "    \n",
    "    Data: in numpy matrix.\n",
    "    label_map: in dictionary.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    text_file = open(file, \"rt\")\n",
    "    reader = csv.reader(text_file, delimiter = delimiter)\n",
    "    x = list(reader)\n",
    "    text_file.close()\n",
    "    \n",
    "    # if there is a header, remove it.\n",
    "    if header:\n",
    "        x.pop(0)\n",
    "    Data = np.asmatrix(x)\n",
    "    \n",
    "    if label_col_is_str:\n",
    "        try:\n",
    "            Data, Label_Map = map_label(Data, label_col)\n",
    "            return Data, Label_Map\n",
    "        except ValueError:\n",
    "            print(\"The header is string data type. Please specify the header = True in the function.\")\n",
    "            Data = None\n",
    "    else:\n",
    "        return Data\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# mapping of the string labels.\n",
    "\n",
    "\n",
    "# mapping the label\n",
    "def map_label(Data, label_column):\n",
    "    \"\"\"\n",
    "    If the label column is string, create a map for the label and convert it to intiger.\n",
    "    \n",
    "    Input:\n",
    "    1. Data: in numpy matrix.\n",
    "    2. label_column: the column number containing the label.\n",
    "    \n",
    "    Output:\n",
    "    1. Data: in numpy matrix in float data type.\n",
    "    \"\"\"\n",
    "    Label_Map = {}\n",
    "    \n",
    "    Label = np.unique(np.array(Data[:, label_column]))\n",
    "    \n",
    "    for i in range(len(Label)):\n",
    "        Label_Map[Label[i]] = i\n",
    "    \n",
    "    mapping = lambda label, label_map : label_map[label]\n",
    "    \n",
    "    Data[:, label_column] = np.vectorize(mapping)(Data[:, label_column], Label_Map)\n",
    "    \n",
    "    Data = Data.astype(float) \n",
    "    \n",
    "    return Data, Label_Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the Data to Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-test data\n",
    "class split_train_test:\n",
    "\n",
    "    \n",
    "    \n",
    "    def __init__(self, data, percentage, label):\n",
    "        '''\n",
    "        Input:\n",
    "        data: a numpy matrix.\n",
    "        percentage: percentage of samples for the training. percentage must be greater than 0 and less than 100.\n",
    "        label: column index of the label.\n",
    "        \n",
    "        \n",
    "        '''\n",
    "\n",
    "        # import necessary module\n",
    "\n",
    "        import numpy as np\n",
    "\n",
    "        # make an one dimensional matrix n*1 to a vecto\n",
    "\n",
    "        make_vector = lambda X : np.squeeze(np.asarray(X))\n",
    "\n",
    "\n",
    "        if percentage <= 0 or percentage >= 100:\n",
    "            print(\"The percentage of training data must be greater than 0 and less than 100.\")\n",
    "        else:\n",
    "            import random;\n",
    "        \n",
    "            n = data.shape[0]  # take the number of rows in original data.\n",
    "            l = int(n*percentage/100)\n",
    "        \n",
    "        \n",
    "            # Take random integers to slice the data\n",
    "            train_rows = random.sample(range(n), l)\n",
    "            test_rows  = [i for i in range(n) if i not in train_rows]\n",
    "            \n",
    "            # Split the data to train and test.\n",
    "            self.train = data[train_rows,:]\n",
    "            self.test  = data[test_rows, :]\n",
    "            \n",
    "            # Split both train and test data to feature and label.\n",
    "            self.train_feature = np.delete(self.train, label, 1)\n",
    "            self.train_label = make_vector(self.train[:, label])\n",
    "            \n",
    "            # Split both train and test data to feature and label.\n",
    "            self.test_feature = np.delete(self.test, label, 1)\n",
    "            self.test_label = make_vector(self.test[:, label])\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K Means Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "\n",
    "def k_means(feature_sample, test_sample, k, iter_conv):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "    feature_sample: The training features without the label.\n",
    "    test_sample: The test features without the label.\n",
    "    k: number of clusters needed.\n",
    "    iter_conv: the limit of iteration for convergence. The number of iteration will not pass this limit. When the limit is reached\n",
    "    the result is produced.\n",
    "    \n",
    "    Output:\n",
    "    centroids: The cluster centroids.\n",
    "    number of iteration done: number of iteration done to reach the results.\n",
    "    cluster index: the cluster indices, which will be corresponding to the cluster controids.\n",
    "    \n",
    "    Solution Structure:\n",
    "    To keep track of the distances a matrix X is prepared with k number of columns(required number of clusters).\n",
    "    The number of rows in X is the number of items in the feature_sample(training data).\n",
    "    \n",
    "    Then X is filled with the distances from each of the initial cluster centroids.\n",
    "    \n",
    "    The initial centroids are taken considering items with minimum distances.\n",
    "    \n",
    "    The means of each of the attributes is the modified centroids. \n",
    "    \n",
    "    \"\"\"\n",
    "    # necessary modules\n",
    "    import random\n",
    "\n",
    "    cluster_indices = None       # to store the cluster indices of the test data.\n",
    "\n",
    "\n",
    "    fdata = feature_sample\n",
    "    data = test_sample\n",
    "    \n",
    "    n, p = data.shape\n",
    "    \n",
    "    \n",
    "    X = np.zeros([n, k])        # matrix X record the distances from centroids.\n",
    "    X.fill(np.nan)\n",
    "\n",
    "    # randomly choose k centroids\n",
    "    random_centroids_row = random.sample(range(n), k)\n",
    "    initial_centroids = fdata[random_centroids_row,]\n",
    "\n",
    "    \n",
    "    \n",
    "    convergence = True\n",
    "    \n",
    "    iteration = 0\n",
    "\n",
    "\n",
    "    make_vector = lambda X : np.squeeze(np.asarray(X)) # this function makes an two dimension n*1 matrix to n item vector.\n",
    "\n",
    "    while(iteration < iter_conv and convergence):\n",
    "        \n",
    "        # Measure distance from each attribute of the feature and centroid and keep it to the matrix X                            \n",
    "\n",
    "        for i in range(n):\n",
    "            for j in range(k):\n",
    "                X[i,j] = euclidean_distance(make_vector(fdata[i]), make_vector(initial_centroids[j,:])) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        initial_cluster = [np.argmin(X[i]) for i in range(n)] # takes the index of the item which is closer to the centroids(the \n",
    "                                                              # column is the mark of initial centroids).\n",
    "        \n",
    "        \n",
    "        # matrix modified_centroid to update the centroid.\n",
    "        modified_centroid = np.zeros([k, p])\n",
    "        modified_centroid.fill(np.nan)\n",
    "        \n",
    "        # take the mean of the initial clusters and update as modified centroids.\n",
    "\n",
    "        for j in range(k):\n",
    "            initial_cluster_features = [initial_cluster[i] == j for i in range(n)]\n",
    "            modified_centroid[j, ] = np.mean(fdata[initial_cluster_features,], axis = 0)\n",
    "            \n",
    "        \n",
    "        # check the convergenc.\n",
    "        if (initial_centroids == modified_centroid).all():\n",
    "            convergence = False\n",
    "        else:\n",
    "            initial_centroids = modified_centroid\n",
    "            iteration += 1\n",
    "\n",
    "    cluster_indices = initial_cluster\n",
    "\n",
    "    return modified_centroid, iteration, cluster_indices\n",
    "\n",
    "\n",
    "import math   \n",
    "\n",
    "## Function for euclidean Distance\n",
    "def euclidean_distance(x, y):\n",
    "    # import math\n",
    "    if len(x) != len(y):\n",
    "        print('Length of two features/vectors are not same.')\n",
    "    else:\n",
    "        n = len(x)\n",
    "        d2 = 0\n",
    "        for i in range(n):\n",
    "            d2 = d2 + (x[i] - y[i])**2\n",
    "        d = math.sqrt(d2)\n",
    "    \n",
    "    return d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation with Iris Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r\"C:\\Users\\tahsi\\OneDrive - University of Eastern Finland\\Python Algorithm and Data Structure\\GitHub\\ml-algorithms-python-numpy\\1. Codes\")\n",
    "Iris, d_map = load_text_data(file = \"Iris.txt\", delimiter = \",\", header = False , label_col_is_str = True , label_col = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.1 3.5 1.4 0.2 0. ]\n",
      " [4.9 3.  1.4 0.2 0. ]\n",
      " [4.7 3.2 1.3 0.2 0. ]\n",
      " [4.6 3.1 1.5 0.2 0. ]\n",
      " [5.  3.6 1.4 0.2 0. ]]\n"
     ]
    }
   ],
   "source": [
    "# first 5 rows of the data. The 5th column was the label. The label was string. The function mapped it to integer. The map of label\n",
    "# is stored in the d_map\n",
    "print(Iris[0:5 ,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Iris-setosa': 0, 'Iris-versicolor': 1, 'Iris-virginica': 2}\n"
     ]
    }
   ],
   "source": [
    "print(d_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Split the Data to Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_data = split_train_test(data = Iris, percentage = 50, label = 4)\n",
    "\n",
    "train_data_feature = train_test_data.train_feature\n",
    "train_data_label = train_test_data.train_label\n",
    "test_feature = train_test_data.test_feature\n",
    "true_label = train_test_data.test_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Implementation of K means algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroids, iteration, cluster_indices = k_means(feature_sample = train_data_feature, test_sample = test_feature, k = 3, iter_conv = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.93714286 2.76285714 4.45428571 1.45142857]\n",
      " [6.84285714 3.12142857 5.68571429 1.97857143]\n",
      " [4.98461538 3.43461538 1.43076923 0.21923077]]\n"
     ]
    }
   ],
   "source": [
    "print(centroids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n"
     ]
    }
   ],
   "source": [
    "print(iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 1, 0, 0, 2, 2, 1, 2, 0, 0, 2, 1, 0, 2, 1, 2, 2, 1, 2, 2, 2, 0, 0, 0, 0, 1, 0, 0, 2, 0, 2, 1, 2, 2, 0, 0, 2, 0, 1, 1, 0, 0, 0, 0, 0, 2, 0, 1, 2, 2, 0, 0, 2, 1, 2, 2, 1, 0, 2, 0, 0, 1, 0, 0, 0, 2, 0, 0, 0, 2, 2, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(cluster_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
